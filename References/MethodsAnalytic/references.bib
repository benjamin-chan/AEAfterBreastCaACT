@article {SIM:SIM3964,
author = {Cai, Tianxi and Parast, Layla and Ryan, Louise},
title = {Meta-analysis for rare events},
journal = {Statistics in Medicine},
volume = {29},
number = {20},
publisher = {John Wiley & Sons, Ltd.},
issn = {1097-0258},
url = {http://dx.doi.org/10.1002/sim.3964},
doi = {10.1002/sim.3964},
pages = {2078--2089},
keywords = {cardiac complications, rosiglitazone, Poisson random effects},
year = {2010},
abstract = {Meta-analysis provides a useful framework for combining information across related studies and has been widely utilized to combine data from clinical studies in order to evaluate treatment efficacy. More recently, meta-analysis has also been used to assess drug safety. However, because adverse events are typically rare, standard methods may not work well in this setting. Most popular methods use fixed or random effects models to combine effect estimates obtained separately for each individual study. In the context of very rare outcomes, effect estimates from individual studies may be unstable or even undefined. We propose alternative approaches based on Poisson random effects models to make inference about the relative risk between two treatment groups. Simulation studies show that the proposed methods perform well when the underlying event rates are low. The methods are illustrated using data from a recent meta-analysis (N. Engl. J. Med. 2007; 356(24):2457–2471) of 48 comparative trials involving rosiglitazone, a type 2 diabetes drug, with respect to its possible cardiovascular toxicity. Copyright © 2010 John Wiley & Sons, Ltd.},
}

@article {SIM:SIM6383,
author = {Kuss, O.},
title = {Statistical methods for meta-analyses including information from studies without any events—add nothing to nothing and succeed nevertheless},
journal = {Statistics in Medicine},
issn = {1097-0258},
url = {http://dx.doi.org/10.1002/sim.6383},
doi = {10.1002/sim.6383},
pages = {n/a--n/a},
keywords = {meta-analysis, safety, sparse data, rare events, continuity correction},
year = {2014},
abstract = {Meta-analyses with rare events, especially those that include studies with no event in one (‘single-zero’) or even both (‘double-zero’) treatment arms, are still a statistical challenge. In the case of double-zero studies, researchers in general delete these studies or use continuity corrections to avoid them. A number of arguments against both options has been given, and statistical methods that use the information from double-zero studies without using continuity corrections have been proposed. In this paper, we collect them and compare them by simulation. This simulation study tries to mirror real-life situations as completely as possible by deriving true underlying parameters from empirical data on actually performed meta-analyses. It is shown that for each of the commonly encountered effect estimators valid statistical methods are available that use the information from double-zero studies without using continuity corrections. Interestingly, all of them are truly random effects models, and so also the current standard method for very sparse data as recommended from the Cochrane collaboration, the Yusuf–Peto odds ratio, can be improved on. For actual analysis, we recommend to use beta-binomial regression methods to arrive at summary estimates for the odds ratio, the relative risk, or the risk difference. Methods that ignore information from double-zero studies or use continuity corrections should no longer be used. We illustrate the situation with an example where the original analysis ignores 35 double-zero studies, and a superior analysis discovers a clinically relevant advantage of off-pump surgery in coronary artery bypass grafting. Copyright © 2014 John Wiley & Sons, Ltd.},
}

@article {SIM:SIM1761,
author = {J. Sweeting, Michael and J. Sutton, Alexander and C. Lambert, Paul},
title = {What to add to nothing? Use and avoidance of continuity corrections in meta-analysis of sparse data},
journal = {Statistics in Medicine},
volume = {23},
number = {9},
publisher = {John Wiley & Sons, Ltd.},
issn = {1097-0258},
url = {http://dx.doi.org/10.1002/sim.1761},
doi = {10.1002/sim.1761},
pages = {1351--1375},
keywords = {meta-analysis, continuity corrections, zero cells, method comparison, sparse data},
year = {2004},
abstract = {Objectives: To compare the performance of different meta-analysis methods for pooling odds ratios when applied to sparse event data with emphasis on the use of continuity corrections.Background: Meta-analysis of side effects from RCTs or risk factors for rare diseases in epidemiological studies frequently requires the synthesis of data with sparse event rates. Combining such data can be problematic when zero events exist in one or both arms of a study as continuity corrections are often needed, but, these can influence results and conclusions.Methods: A simulation study was undertaken comparing several meta-analysis methods for combining odds ratios (using various classical and Bayesian methods of estimation) on sparse event data. Where required, the routine use of a constant and two alternative continuity corrections; one based on a function of the reciprocal of the opposite group arm size; and the other an empirical estimate of the pooled effect size from the remaining studies in the meta-analysis, were also compared. A number of meta-analysis scenarios were simulated and replicated 1000 times, varying the ratio of the study arm sizes.Results: Mantel–Haenszel summary estimates using the alternative continuity correction factors gave the least biased results for all group size imbalances. Logistic regression was virtually unbiased for all scenarios and gave good coverage properties. The Peto method provided unbiased results for balanced treatment groups but bias increased with the ratio of the study arm sizes. The Bayesian fixed effect model provided good coverage for all group size imbalances. The two alternative continuity corrections outperformed the constant correction factor in nearly all situations. The inverse variance method performed consistently badly, irrespective of the continuity correction used.Conclusions: Many routinely used summary methods provide widely ranging estimates when applied to sparse data with high imbalance between the size of the studies' arms. A sensitivity analysis using several methods and continuity correction factors is advocated for routine practice. Copyright 2004 John Wiley & Sons, Ltd.},
}

@article{Lane01042013,
author = {Lane, Peter W}, 
title = {Meta-analysis of incidence of rare events},
volume = {22}, 
number = {2}, 
pages = {117-132}, 
year = {2013}, 
doi = {10.1177/0962280211432218}, 
abstract ={This is a review of methods for the meta-analysis of incidence of rare events using summary-level data. It is motivated and illustrated by the dataset used in a published analysis of cardiovascular safety in rosiglitazone trials. This review compares available methods for binary data, considering risk-difference, relative-risk and odds-ratio scales, fixed-effect and random-effects models, and frequentist and Bayesian approaches. Particular issues in this dataset include low incidence rates, the occurrence of studies with no events under one or all treatments, and discrepancy among results achieved using different statistical methodologies. The common method of adding a correction factor to handle zeroes may introduce bias where the incidence of events is small, as in this case. Alternative analyses on the log-odds scale are shown to give similar results, but the choice between them is less important than the potential sources of bias in any meta-analysis arising from limitations in the underlying dataset. It is important to present results carefully, including numerical and graphical summaries on the natural scale of risk when the analysis is on a statistically appropriate scale such as log-odds: the incidence rates should accompany an estimated ratio (of odds or risk) to put the analysis into the proper context. Beyond the statistical methodologies which are the focus of this paper, this dataset highlights the importance of understanding the limitations of the data being combined. Because the rosiglitazone dataset contains clinically heterogeneous trials with low event rates that were not designed or intended to assess cardiovascular outcomes, the findings of any meta-analysis of such trials should be considered hypothesis-generating.}, 
URL = {http://smm.sagepub.com/content/22/2/117.abstract}, 
eprint = {http://smm.sagepub.com/content/22/2/117.full.pdf+html}, 
journal = {Statistical Methods in Medical Research} 
}

@article{Langan2012511,
title = "Graphical augmentations to the funnel plot assess the impact of additional evidence on a meta-analysis ",
journal = "Journal of Clinical Epidemiology ",
volume = "65",
number = "5",
pages = "511 - 519",
year = "2012",
note = "",
issn = "0895-4356",
doi = "http://dx.doi.org/10.1016/j.jclinepi.2011.10.009",
url = "http://www.sciencedirect.com/science/article/pii/S0895435611003271",
author = "Dean Langan and Julian P.T. Higgins and Walter Gregory and Alexander J. Sutton",
keywords = "Study design",
keywords = "Meta-analysis",
keywords = "Graphical display",
keywords = "Evidence-based medicine",
keywords = "Funnel plot",
keywords = "Clinical trial ",
abstract = "Objective We aim to illustrate the potential impact of a new study on a meta-analysis, which gives an indication of the robustness of the meta-analysis. Study Design and Setting A number of augmentations are proposed to one of the most widely used of graphical displays, the funnel plot. Namely, 1) statistical significance contours, which define regions of the funnel plot in which a new study would have to be located to change the statistical significance of the meta-analysis; and 2) heterogeneity contours, which show how a new study would affect the extent of heterogeneity in a given meta-analysis. Several other features are also described, and the use of multiple features simultaneously is considered. Results The statistical significance contours suggest that one additional study, no matter how large, may have a very limited impact on the statistical significance of a meta-analysis. The heterogeneity contours illustrate that one outlying study can increase the level of heterogeneity dramatically. Conclusion The additional features of the funnel plot have applications including 1) informing sample size calculations for the design of future studies eligible for inclusion in the meta-analysis; and 2) informing the updating prioritization of a portfolio of meta-analyses such as those prepared by the Cochrane Collaboration. "
}

@article{doi:10.1080/01621459.2012.664484,
author = {Bhaumik, Dulal K. and Amatya, Anup and Normand, Sharon-Lise T. and Greenhouse, Joel and Kaizar, Eloise and Neelon, Brian and Gibbons, Robert D.},
title = {Meta-Analysis of Rare Binary Adverse Event Data},
journal = {Journal of the American Statistical Association},
volume = {107},
number = {498},
pages = {555-567},
year = {2012},
doi = {10.1080/01621459.2012.664484},
    note ={PMID: 23734068},

URL = { 
        http://dx.doi.org/10.1080/01621459.2012.664484
    
},
eprint = { 
        http://dx.doi.org/10.1080/01621459.2012.664484
    
}
,
    abstract = { We examine the use of fixed-effects and random-effects moment-based meta-analytic methods for analysis of binary adverse-event data. Special attention is paid to the case of rare adverse events that are commonly encountered in routine practice. We study estimation of model parameters and between-study heterogeneity. In addition, we examine traditional approaches to hypothesis testing of the average treatment effect and detection of the heterogeneity of treatment effect across studies. We derive three new methods, a simple (unweighted) average treatment effect estimator, a new heterogeneity estimator, and a parametric bootstrapping test for heterogeneity. We then study the statistical properties of both the traditional and the new methods via simulation. We find that in general, moment-based estimators of combined treatment effects and heterogeneity are biased and the degree of bias is proportional to the rarity of the event under study. The new methods eliminate much, but not all, of this bias. The various estimators and hypothesis testing methods are then compared and contrasted using an example dataset on treatment of stable coronary artery disease. }
}

@article{Viechtbauer:2010:JSSOBK:v36i03,
  author =	"Wolfgang Viechtbauer",
  title =	"Conducting Meta-Analyses in R with the metafor Package",
  journal =	"Journal of Statistical Software",
  volume =	"36",
  number =	"3",
  pages =	"1--48",
  day =  	"5",
  month =	"8",
  year = 	"2010",
  CODEN =	"JSSOBK",
  ISSN = 	"1548-7660",
  bibdate =	"2010-06-24",
  URL =  	"http://www.jstatsoft.org/v36/i03",
  accepted =	"2010-06-24",
  acknowledgement = "",
  keywords =	"",
  submitted =	"2009-09-16",
}
